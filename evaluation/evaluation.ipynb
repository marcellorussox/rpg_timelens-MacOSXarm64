{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Toolbox di Valutazione per l'Interpolazione di Frame con TimeLens\n",
    "\n",
    "## Introduzione\n",
    "Questo notebook implementa il calcolo delle metriche MSE, PSNR, SSIM e LPIPS per la valutazione di frame interpolati. I dati devono essere organizzati in una struttura specifica:\n",
    "\n",
    "### Struttura delle Cartelle\n",
    "    \n",
    "    └── results_folder\n",
    "            ├── sequence_0\n",
    "            │   ├── GT               <------ Dove sono salvate le immagini di ground truth\n",
    "            │   │   ├── 000000.png\n",
    "            │   │   ├── 000001.png\n",
    "            │   │   └── ...\n",
    "            │   ├── method_0          <------ Il primo metodo da valutare\n",
    "            │   │   ├── 000000.png\n",
    "            │   │   ├── 000001.png\n",
    "            │   │   └── ...\n",
    "            │   ├── method_1\n",
    "            │   │   ├── 000000.png\n",
    "            │   │   ├── 000001.png\n",
    "            │   │   └── ...\n",
    "            │   └── ...\n",
    "            ├── sequence_1\n",
    "            │   ├── GT\n",
    "            │   │   ├── 000000.png\n",
    "            │   │   ├── 000001.png\n",
    "            │   │   └── ...\n",
    "            │   └── ...\n",
    "            └── ...\n",
    "            \n",
    "## Requisiti\n",
    "- Python 3.x\n",
    "- Librerie: `numpy`, `cv2`, `lpips`"
   ],
   "id": "6aa52ddf6a937ba7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:03:36.389520Z",
     "start_time": "2025-01-18T14:03:21.587066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importa librerie necessarie\n",
    "import os\n",
    "from os.path import join, basename\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import lpips\n",
    "\n",
    "# Inizializza LPIPS\n",
    "loss_fn = lpips.LPIPS(net='vgg')  # Usa 'alex' o 'vgg'"
   ],
   "id": "2e5b75cd56d5722a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <FB2FD416-6C4D-3621-B677-61F07C02A3C5> /opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/homebrew/Caskroom/miniforge/base/envs/timelens/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/marcello/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:12<00:00, 45.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T23:40:46.445268Z",
     "start_time": "2025-01-18T23:40:46.437060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from evaluation import compute_mse, compute_psnr, compute_ssim, compute_lpips\n",
    "\n",
    "\n",
    "def process_dataset(gt_files, pred_files, num_skips, grayscale):\n",
    "    metrics = {\"MSE\": [], \"PSNR\": [], \"SSIM\": [], \"LPIPS\": []}\n",
    "\n",
    "    for i, (gt_path, pred_path) in enumerate(zip(gt_files, pred_files)):\n",
    "        if i % (num_skips + 1) != 0:\n",
    "            continue\n",
    "\n",
    "        gt_img = cv2.imread(gt_path)\n",
    "        pred_img = cv2.imread(pred_path)\n",
    "\n",
    "        if gt_img is None or pred_img is None or gt_img.shape != pred_img.shape:\n",
    "            print(f\"Errore con immagini: GT={gt_path}, Pred={pred_path}\")\n",
    "            continue\n",
    "\n",
    "        if grayscale:\n",
    "            gt_img = cv2.cvtColor(gt_img, cv2.COLOR_BGR2GRAY)\n",
    "            pred_img = cv2.cvtColor(pred_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        try:\n",
    "            metrics[\"MSE\"].append(compute_mse(gt_img, pred_img))\n",
    "            metrics[\"PSNR\"].append(compute_psnr(gt_img, pred_img))\n",
    "            metrics[\"SSIM\"].append(compute_ssim(gt_img, pred_img))\n",
    "            metrics[\"LPIPS\"].append(compute_lpips(gt_img, pred_img))\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel calcolo metriche: {e}\")\n",
    "\n",
    "    return metrics"
   ],
   "id": "a801ede2b34686d0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T23:40:47.048579Z",
     "start_time": "2025-01-18T23:40:47.038073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(parent_folder, filter_string=\"test\", num_skips=0, grayscale=False):\n",
    "    \"\"\"\n",
    "    Valuta tutti i dataset all'interno delle cartelle che includono la stringa `filter_string`.\n",
    "\n",
    "    Args:\n",
    "        parent_folder (str): Cartella principale contenente le cartelle come ev_test, ev_test2, ecc.\n",
    "        filter_string (str): Stringa da usare per filtrare le directory principali.\n",
    "        num_skips (int): Numero di frame da saltare per la valutazione.\n",
    "        grayscale (bool): Se True, converte le immagini in scala di grigi prima della valutazione.\n",
    "    \"\"\"\n",
    "    # Trova tutte le directory principali che contengono il filtro\n",
    "    main_folders = [d for d in sorted(glob.glob(join(parent_folder, f\"*{filter_string}*\"))) if os.path.isdir(d)]\n",
    "\n",
    "    if not main_folders:\n",
    "        print(f\"Nessuna cartella trovata con il filtro '{filter_string}' in {parent_folder}\")\n",
    "        return\n",
    "\n",
    "    # Itera attraverso ogni cartella principale (es. ev_test, ev_test2, ...)\n",
    "    for main_folder in main_folders:\n",
    "        print(f\"\\n--- Analisi in {main_folder} ---\")\n",
    "\n",
    "        # Trova tutte le sottocartelle dei dataset (es. baloon_popping, spinning_plate, ecc.)\n",
    "        dataset_folders = [d for d in sorted(glob.glob(join(main_folder, \"*\"))) if os.path.isdir(d)]\n",
    "\n",
    "        if not dataset_folders:\n",
    "            print(f\"Nessun dataset trovato in {main_folder}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Processa ogni dataset\n",
    "        for dataset_path in dataset_folders:\n",
    "            dataset_name = basename(dataset_path)\n",
    "            print(f\"\\n--- Dataset: {dataset_name} ---\")\n",
    "\n",
    "            # Trova le sottocartelle (GT, Timelens, ecc.)\n",
    "            subfolders = [f for f in sorted(glob.glob(join(dataset_path, \"*\"))) if os.path.isdir(f)]\n",
    "            method_files = {basename(sf): sorted(glob.glob(join(sf, \"*.png\"))) for sf in subfolders}\n",
    "\n",
    "            # Controlla se esiste la cartella GT\n",
    "            if \"GT\" not in method_files:\n",
    "                print(f\"Manca cartella GT in {dataset_name}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Estrai i file di GT\n",
    "            gt_files = method_files.pop(\"GT\")\n",
    "\n",
    "            # Processa ogni metodo (es. Timelens, AltroMetodo, ecc.)\n",
    "            for method_name, pred_files in method_files.items():\n",
    "                if len(gt_files) != len(pred_files):\n",
    "                    print(f\"Mismatch file GT({len(gt_files)}) e {method_name}({len(pred_files)})\")\n",
    "                    continue\n",
    "\n",
    "                # Calcola le metriche\n",
    "                metrics = process_dataset(gt_files, pred_files, num_skips, grayscale)\n",
    "                print(f\"Metodo: {method_name}\")\n",
    "                for metric, values in metrics.items():\n",
    "                    mean = np.mean(values)\n",
    "                    std = np.std(values)\n",
    "                    print(f\"  {metric}: {mean:.4f} ± {std:.4f}\")"
   ],
   "id": "ed5e8d8d2cb5cb33",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T23:43:32.586118Z",
     "start_time": "2025-01-18T23:40:47.978727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parametri\n",
    "test_folder = \"test_folder\"\n",
    "num_skips = 1  # Numero di frame da saltare\n",
    "grayscale = False  # Calcolo in scala di grigi\n",
    "\n",
    "evaluate(test_folder, num_skips=num_skips, grayscale=grayscale)"
   ],
   "id": "a39a7ed719e2ef6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analisi in test_folder/ev_test ---\n",
      "\n",
      "--- Dataset: baloon_popping ---\n",
      "Metodo: Timelens\n",
      "  MSE: 19.3768 ± 1.1346\n",
      "  PSNR: 33.7382 ± 1.2608\n",
      "  SSIM: 0.7603 ± 0.0449\n",
      "  LPIPS: nan ± nan\n",
      "\n",
      "--- Analisi in test_folder/ev_test2 ---\n",
      "\n",
      "--- Dataset: fountaine ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/timelens/lib/python3.9/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metodo: Timelens\n",
      "  MSE: 162.3000 ± 29.2467\n",
      "  PSNR: 25.9236 ± 0.6333\n",
      "  SSIM: 0.6640 ± 0.0230\n",
      "  LPIPS: nan ± nan\n",
      "\n",
      "--- Dataset: spinning_plate ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m num_skips \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m  \u001B[38;5;66;03m# Numero di frame da saltare\u001B[39;00m\n\u001B[1;32m      4\u001B[0m grayscale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# Calcolo in scala di grigi\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_skips\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_skips\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrayscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrayscale\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[24], line 53\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(parent_folder, filter_string, num_skips, grayscale)\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# Calcola le metriche\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgt_files\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred_files\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_skips\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrayscale\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMetodo: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmethod_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m metric, values \u001B[38;5;129;01min\u001B[39;00m metrics\u001B[38;5;241m.\u001B[39mitems():\n",
      "Cell \u001B[0;32mIn[23], line 12\u001B[0m, in \u001B[0;36mprocess_dataset\u001B[0;34m(gt_files, pred_files, num_skips, grayscale)\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m     11\u001B[0m gt_img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(gt_path)\n\u001B[0;32m---> 12\u001B[0m pred_img \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gt_img \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m pred_img \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m gt_img\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m pred_img\u001B[38;5;241m.\u001B[39mshape:\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mErrore con immagini: GT=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgt_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Pred=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c6519ec0b17c5a0a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
